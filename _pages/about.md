---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a first-year CS Ph.D. Student at [Dartmouth College](https://home.dartmouth.edu). I got my master's degree from [The Chinese University of Hongkong, Shenzhen](https://www.cuhk.edu.cn/en), advised by Prof. [Xiaoguang Han](https://scholar.google.com/citations?user=z-rqsR4AAAAJ&hl=zh-CN). Before that, I received my bachelor's degree from [Shanghai Jiao Tong University](https://en.sjtu.edu.cn/).

I was previously a research intern at [Alibaba DAMO Academy](https://damo.alibaba.com/research-areas?language=en) for 5 wonderful months. I was previously a Visiting Student working with Prof. [Ming-Hsuan Yang](https://scholar.google.com/citations?user=p9-ohHsAAAAJ&hl=zh-CN) at [UC Merced](https://www.ucmerced.edu/) and Prof. [Chao Ma](https://scholar.google.com/citations?user=syoPhv8AAAAJ&hl=zh-CN) at [AI Institute](https://ai.sjtu.edu.cn), [Shanghai Jiao Tong University](https://en.sjtu.edu.cn/). I work closely with Dr. [Lu Qi](https://scholar.google.com.hk/citations?user=SSI90d4AAAAJ&hl=en), Dr. [Xiangtai Li](https://scholar.google.com/citations?user=FL3ReD0AAAAJ&hl=zh-CN) at **Tiktok**. I was previously a Research Assistant at AI Thrust, [The Hong Kong University of Science and Technology (Guangzhou)](https://www.hkust-gz.edu.cn/), supervised by Prof. [Junwei Liang](https://scholar.google.com/citations?user=bMedjfUAAAAJ&hl=en). I also work closely with Dr. [Peijie Dong](https://scholar.google.com/citations?user=TqS6s4gAAAAJ&hl=zh-CN) at **HKUST(GZ)**.

My previous research experience mainly lies in Video Prediction.

My long-term research interests lie in:

* Multimodal Large Language Models
* Video Understanding
* Unfied Understanding and Generation Model
* Visual Tokenzier

<div style="color: red;">
    I‚Äôm open for academic collaborations. If you are interested, please feel free to email me (tangyujin0275@gmail.com).

</div>

# üìñ Educations

- *2025.09 - 2030.07(expected)*, Ph.D, **Dartmouth College**, Computer Science
- *2021.09 - 2023.07*, MSc, **The Chinese University of Hongkong, Shenzhen**, Data Science
- *2017.09 - 2021.06*, Bachelor, **Shanghai Jiao Tong University**, Biomedical Engineering

# üíª Internships

- *2025.03 -2025.07,* Algorithm Engineer Intern, **Alibaba DAMO Academy**
- *2024.06 - 2025.03,* Remote Visiting Student @ **UC Merced** and Onsite Visiting Student @ **Shanghai Jiao Tong University**
- *2023.02 - 2024.05,* Research Assistant, **The Hong Kong University of Science and Technology (Guangzhou)**
- *2021.07 - 2022.02*, Reseach Assistant, **Shenzhen Research Institute of Big Data**

# üî• News

- *2025.09*: &nbsp;Yujin enrolled in Dartmouth College as a Ph.D. student in Computer Science.
- *2025.03*: &nbsp;Yujin joined Alibaba DAMO Academy as a research intern.
- *2024.10*: &nbsp;PredFormer is available!  This is the first pure-transformer based model in spatial-temporal predictive learning, which is recurrent-free and convolution-free, outperforming previous models by large margins with superior efficiency. [**Paper**](https://arxiv.org/abs/2410.04733) [ **Code**](https://github.com/yyyujintang/PredFormer) ![Stars](https://img.shields.io/github/stars/yyyujintang/PredFormer)
- *2024.04*: &nbsp;üéâüéâ VMRNN was accepted by [CVPRW24](https://sites.google.com/view/ieeecvf-cvpr2024-precognition)!
- *2024.03*: &nbsp;Yujin was invited to give a talk in CUHKSZ in Data Science College. Congratulations to the 10th anniversary of CUHKSZ! üéâüéâ [Slides](https://docs.google.com/presentation/d/1JyFRflVfvXNLgOVdD7ZGX0llscv4voW8k5qLfsbRSpg/edit?usp=sharing)
- *2024.03*: &nbsp;üéâüéâ PostRainBench was accepted by [ICLRW24](https://www.climatechange.ai/events/iclr2024)!
- *2024.01*: &nbsp;Yujin created Awesome-Mamba-Papers repository and keep updating it. **This is the first Awesome Mamba repository and promotes Mamba related research**. [Link](https://github.com/yyyujintang/Awesome-Mamba-Papers) ![Stars](https://img.shields.io/github/stars/yyyujintang/Awesome-Mamba-Papers)
- *2023.07*: &nbsp;üéâüéâ Yujin won Excellence Award in Jinan, Shandong in 0-24 hours Precipitation Nowcasting Challenge! [Slides](https://docs.google.com/presentation/d/1NTxQQr-b-zcBdQkIx42IhUKVZgKbo5U7QDIxCo0q-Qw/edit?usp=sharing)
- *2023.01*: &nbsp;Yujin served as TA for AIAA 5032 Foundations of Artificial Intelligence in HKUSTGZ, Spring 2023, Instructors: Junwei Liang.

# üìù Publication & PrePrint

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv, 2024</div><img src='images/PredFormer.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Video Prediction Transformers without Recurrence or Convolution

**Yujin Tang**, Lu Qi, Fei Xie, Xiangtai Li, Chao Ma, Ming-Hsuan Yang

[ **Paper**](https://arxiv.org/abs/2410.04733)  [**Website**](https://yyyujintang.github.io/predformer-project/)  [**Code**](https://github.com/yyyujintang/PredFormer) ![Stars](https://img.shields.io/github/stars/yyyujintang/PredFormer) [Áü•‰πé](https://zhuanlan.zhihu.com/p/938884694) [Êó∂Á©∫Êé¢Á¥¢‰πãÊóÖ](https://mp.weixin.qq.com/s/hkUyFnwwrIOMJYA6yVQ6_Q) [ÂúÜÂúÜÁöÑÁÆóÊ≥ïÁ¨îËÆ∞](https://mp.weixin.qq.com/s/SmVYqvoDJ5fm8KxEEX8dqg) [CVer](https://mp.weixin.qq.com/s/_NJAawEt_7TC8fFZP7gh5A) [KaggleÁ´ûËµõÂÆùÂÖ∏](https://mp.weixin.qq.com/s/QLF-DBqeHaor3morIlWC5w) [Ê∑±Â∫¶Â≠¶‰π†Â∑•Âùä](https://mp.weixin.qq.com/s/ejhUnpkQcsaMYFoRKyK40A) [ÊàëÁà±ËÆ°ÁÆóÊú∫ËßÜËßâ](https://mp.weixin.qq.com/s/OMks7JRIIZlbvXJEO7TAgg)

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR Precognition Workshop, 2024</div><img src='images/VMRNN_Cell.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

VMRNN: Integrating Vision Mamba and LSTM for Efficient and Accurate Spatiotemporal Forecasting

**Yujin Tang**, Peijie Dong, Zhenheng Tang, Xiaowen Chu, Junwei Liang

[ **Paper**](https://arxiv.org/abs/2403.16536)  [**Code**](https://github.com/yyyujintang/VMRNN-PyTorch) ![Stars](https://img.shields.io/github/stars/yyyujintang/VMRNN-PyTorch)

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR Workshop, 2024</div><img src='images/PostRainBench.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

PostRainBench: A comprehensive benchmark and a new model for precipitation forecasting

**Yujin Tang**, Jiaming Zhou, Xiang Pan, Zeying Gong, Junwei Liang

[ **Paper**](https://arxiv.org/abs/2310.02676) [ **Code**](https://github.com/yyyujintang/PostRainBench) ![Stars](https://img.shields.io/github/stars/yyyujintang/PostRainBench)

</div>
</div>

Long Video Understanding

# üìï Notes

Computer Vision PhD Survival Guide Series(1) CV Paper Tracking and Writing [Link](https://zhuanlan.zhihu.com/p/610774199)

Computer Vision PhD Survival Guide Series(2) Code Release Process and Tools  [Link](https://zhuanlan.zhihu.com/p/611491695)

Computer Vision PhD Survival Guide Series(3) SSH Configuration and Common Linux Command  [Link](https://zhuanlan.zhihu.com/p/676491841)

# üîó Resources for CV Researchers

[Ming-Hsuan Yang-UCM](https://scholar.google.com/citations?user=syoPhv8AAAAJ&hl=en): How to Get Your CVPR Paper Rejected? [Link](https://vision.sjtu.edu.cn/files/How-to-get-your-CVPR-paper-rejected.pdf)

[Chao Ma-SJTU](https://scholar.google.com/citations?user=syoPhv8AAAAJ&hl=en): (Collection) Research and Writing Tips for Computer Vision Researchers [Link](https://vision.sjtu.edu.cn/writing.html)

[Sida Peng-ZJU](https://scholar.google.com/citations?hl=zh-CN&user=l9NCksYAAAAJ): The Process of Finishing a Research Project [Link](https://github.com/pengsida/learning_research)

[Bolei Zhou-UCLA](https://scholar.google.com/citations?hl=zh-CN&user=9D4aG8AAAAAJ): How to Make Posters for Top Conference Paper [Link](https://github.com/zhoubolei/bolei_awesome_posters)

[Yana Hasson-Inria](https://scholar.google.com/citations?hl=zh-CN&user=yhz7sFoAAAAJ): Useful Computer Vision PhD Resources [Link](https://github.com/hassony2/useful-computer-vision-phd-resources)

[Bill Freeman-MIT](https://scholar.google.com/citations?user=0zZnyMEAAAAJ&hl=zh-CN): How to Write Papers [Link](https://faculty.cc.gatech.edu/~parikh/citizenofcvpr/static/slides/freeman_how_to_write_papers.pdf) Advice for Graduate Student  [Link](https://people.csail.mit.edu/billf/talks/10minFreeman2013.pdf)

**Thanks a lot to these generous people for sharing their valuable research experience!**

'She is a first-generation college student born in a small city in western China. She constantly overcomes environmental resistance, builds a strong spiritual core, and pushes herself to grow and progress with self-drive and self-discipline. Thinking before practice, iterating quickly in action, she aims to make beneficial changes to the world with artificial intelligence and promote social equity.'

<script type="text/javascript" id="mapmyvisitors" src="https://mapmyvisitors.com/map.js?d=DpZkNL3LsLmeQRxUKn0lTTI5TvgkpddDlnJpErWoftQ&cl=ffffff&w=a"></script>
